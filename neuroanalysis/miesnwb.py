import sys
from datetime import datetime
from collections import OrderedDict
import numpy as np
import h5py


class MiesNwb(object):
    """Class for accessing data from a MIES-generated NWB file.
    """
    def __init__(self, filename):
        self.filename = filename
        self.hdf = h5py.File(filename, 'r')
        self._sweeps = None
        self._groups = None
        self._notebook = None
        
    def notebook(self):
        """Return compiled data from the lab notebook.

        The format is a dict like ``{sweep_number: [ch1, ch2, ...]}`` that contains one key:value
        pair per sweep. Each value is a list containing one metadata dict for each channel in the
        sweep. For example::

            nwb.notebook()[sweep_id][channel_id][metadata_key]
        """
        if self._notebook is None:
            # collect all lab notebook entries
            nb_entries = OrderedDict()
            nb_keys = self.hdf['general']['labnotebook']['ITC1600_Dev_0']['numericalKeys'][0]
            nb_fields = OrderedDict([(k, i) for i,k in enumerate(nb_keys)])
            nb = self.hdf['general']['labnotebook']['ITC1600_Dev_0']['numericalValues']

            # EntrySourceType field is needed to distinguish between records created by TP vs sweep
            entry_source_type_index = nb_fields.get('EntrySourceType', None)
            
            nb_iter = iter(range(nb.shape[0]))  # so we can skip multiple rows from within the loop
            for i in nb_iter:
                rec = nb[i]
                sweep_num = rec[0,0]

                # ignore records with no associated sweep
                if np.isnan(sweep_num):
                    continue

                # ignore records that were generated by test pulse
                # (note: entrySourceType is nan if an older pxp is re-exported to nwb using newer MIES)
                if entry_source_type_index is not None and not np.isnan(rec[entry_source_type_index][0]):
                    if rec[entry_source_type_index][0] != 0:
                        continue
                elif i < nb.shape[0] - 1:
                    # Older files may be missing EntrySourceType. In this case, we can identify TP blocks
                    # as two records containing a "TP Peak Resistance" value in the first record followed
                    # by a "TP Pulse Duration" value in the second record.
                    tp_peak = rec[nb_fields['TP Peak Resistance']]
                    if any(np.isfinite(tp_peak)):
                        tp_dur = nb[i+1][nb_fields['TP Pulse Duration']]
                        if any(np.isfinite(tp_dur)):
                            nb_iter.next()
                            continue

                sweep_num = int(sweep_num)
                # each sweep gets multiple nb records; for each field we use the last non-nan value in any record
                if sweep_num not in nb_entries:
                    nb_entries[sweep_num]= np.array(rec)
                else:
                    mask = ~np.isnan(rec)
                    nb_entries[sweep_num][mask] = rec[mask]

            for swid, entry in nb_entries.items():
                # last column applies to all channels
                mask = ~np.isnan(entry[:,8])
                entry[mask] = entry[:,8:9][mask]
    
                # first 4 fields of first column apply to all channels
                entry[:4] = entry[:4, 0:1]

                # convert to list-o-dicts
                meta = []
                for i in range(entry.shape[1]):
                    tm = entry[:, i]
                    meta.append(OrderedDict([(nb_keys[j], (None if np.isnan(tm[j]) else tm[j])) for j in range(len(nb_keys))]))
                nb_entries[swid] = meta

            self._notebook = nb_entries
        return self._notebook

    def sweeps(self):
        """Return a list of all sweeps in this file.
        """
        if self._sweeps is None:
            sweeps = set()
            for k in self.hdf['acquisition/timeseries'].keys():
                a, b, c = k.split('_')
                sweeps.add(b)
            self._sweeps = [Sweep(self, int(sweep_id)) for sweep_id in sorted(list(sweeps))]
        return self._sweeps
    
    def sweep_groups(self, keys=('shape', 'stim_name', 'V-Clamp Holding Level', 'Clamp Mode')):
        """Return a list of sweep groups--each group contains one or more
        contiguous sweeps with matching metadata.

        The *keys* argument contains the set of metadata keys that are compared
        to determine group boundaries.

        This is used mainly for grouping together sweeps that were repeated or were 
        part of a stim set.
        """
        keys = list(keys)
        if 'shape' in keys:
            group_by_shape = True
            keys.remove('shape')
        else:
            group_by_shape = False

        if self._groups is None:
            current_group = []
            current_meta = None
            groups = [current_group]
            for sweep in self.sweeps():
                # get selected metadata for grouping sweeps
                meta = {}
                for ch in sweep.channels():
                    trace = sweep.traces()[ch]
                    m = trace.meta()
                    meta[ch] = {k:m[k] for k in keys}
                    if group_by_shape:
                        meta[ch]['shape'] = len(trace)

                if len(current_group) == 0:
                    current_group.append(sweep)
                    current_meta = meta
                else:
                    if meta == current_meta:
                        current_group.append(sweep)
                    else:
                        current_group = [sweep]
                        current_meta = meta
                        groups.append(current_group)
            self._groups = [SweepGroup(self, grp) for grp in groups]
        return self._groups

    @staticmethod
    def pack_sweep_data(sweeps):
        """Return a single array containing all data from a list of sweeps.
        
        The array shape is (sweeps, channels, samples, 2), where the final axis
        contains recorded data at index 0 and the stimulus at index 1.

        All sweeps must have the same length and number of channels.
        """
        sweeps = [s.data() for s in sweeps]
        data = np.empty((len(sweeps),) + sweeps[0].shape, dtype=sweeps[0].dtype)
        for i in range(len(sweeps)):
            data[i] = sweeps[i]
        return data

    @staticmethod
    def igorpro_date(timestamp):
        """Convert an IgorPro timestamp (seconds since 1904-01-01) to a datetime
        object.
        """
        dt = datetime(1970,1,1) - datetime(1904,1,1)
        return datetime.utcfromtimestamp(timestamp) - dt


class Trace(object):
    """A single stimulus / recording made on a single channel.
    """
    def __init__(self, sweep, sweep_id, ad_chan):
        self.sweep = sweep
        self.nwb = sweep.nwb
        self.trace_id = (sweep_id, ad_chan)
        self.hdf_group = self.nwb.hdf['acquisition/timeseries/data_%05d_AD%d' % self.trace_id]
        self.headstage_id = int(self.hdf_group['electrode_name'].value[0].split('_')[1])
        self._meta = None
        self._da_chan = None
        self._data = None

    def data(self):
        """Return an array of shape (N, 2) containing the recording and stimulus
        for this trace.

        The first column [:, 0] contains recorded data and the second column [:, 1]
        contains the stimulus.
        """
        if self._data is None:
            # scale data based on clamp mode
            scales = (1e-12, 1e-3) if self.meta()['Clamp Mode'] == 0 else (1e-3, 1e-12)
            self._data = np.vstack([np.array(self.recording()) * scales[0], np.array(self.stim()) * scales[1]]).T
        return self._data

    def __len__(self):
        return len(self.recording())

    def recording(self):
        """Return the raw recorded data for this trace.
        """
        return self.hdf_group['data']        

    @property
    def sample_rate(self):
        # Note: this is also available in meta()['Minimum Sampling interval'],
        # but that key is missing in some older NWB files.
        return self.recording().attrs['IGORWaveScaling'][1,0] 
        
    def da_chan(self):
        """Return the DA channel ID for this trace.
        """
        if self._da_chan is None:
            hdf = self.nwb.hdf['stimulus/presentation']
            stims = [k for k in hdf.keys() if k.startswith('data_%05d_'%self.trace_id[0])]
            for s in stims:
                elec = hdf[s]['electrode_name'].value[0]
                if elec == 'electrode_%d' % self.headstage_id:
                    self._da_chan = int(s.split('_')[-1][2:])
            if self._da_chan is None:
                raise Exception("Cannot find DA channel for headstage %d" % self.headstage_id)
        return self._da_chan

    def stim(self):
        """Return the raw stimulus array for this trace.
        """
        return self.nwb.hdf['stimulus/presentation/data_%05d_DA%d/data' % (self.trace_id[0], self.da_chan())]

    def meta(self):
        """Return a dict of metadata for this trace.

        Keys include 'stim_name', 'start_time', and all parameters recorded in the lab notebook.
        """
        if self._meta is None:
            self._meta = OrderedDict()
            self._meta['stim_name'] = self.hdf_group['stimulus_description'].value[0]
            self._meta['start_time'] = self.hdf_group['starting_time'].value[0]
            self._meta['headstage'] = self.headstage_id
            nb = self.nwb.notebook()[int(self.trace_id[0])][self.headstage_id]
            self._meta.update(nb)
        return self._meta

    def __repr__(self):
        meta = self.meta()
        mode = meta['Clamp Mode']
        if mode == 0:  # VC
            extra = "mode=VC holding=%d" % int(np.round(meta['V-Clamp Holding Level']))
        elif mode == 1:  # IC
            extra = "mode=IC holding=%d" % int(np.round(meta['I-Clamp Holding Level']))

        return "<Trace %d.%d  stim=%s %s>" % (self.trace_id[0], self.headstage_id, meta['stim_name'], extra)


class Sweep(object):
    """Represents one recorded sweep with multiple channels.
    """
    def __init__(self, nwb, sweep_id):
        self.nwb = nwb
        self.sweep_id = sweep_id
        self._channels = None
        self._meta = None
        self._traces = None
        self._notebook_entry = None

    def channels(self):
        """Return a list of AD channels participating in this sweep.
        """
        if self._channels is None:
            chans = []
            for k in self.nwb.hdf['acquisition/timeseries'].keys():
                if not k.startswith('data_%05d_' % self.sweep_id):
                    continue
                chans.append(int(k.split('_')[-1][2:]))
            self._channels = sorted(chans)
        return self._channels

    def traces(self):
        """Return a dict of Traces in this sweep, one per channel.
        """
        if self._traces is None:
            self._traces = OrderedDict([(ch, Trace(self, self.sweep_id, ch)) for ch in self.channels()])
        return self._traces

    def meta(self, all_chans=False):
        """Return a dict containing the metadata key/value pairs that are shared
        across all traces in this sweep.

        If *all_chans* is True, then instead return a list of values for each meta key.
        """
        if all_chans:
            m = OrderedDict()
            for trace in self.traces().values():
                for k,v in trace.meta().items():
                    if k not in m:
                        m[k] = []
                    m[k].append(v)
            return m

        else:
            if self._meta is None:
                traces = [self.traces()[chan] for chan in self.channels()]
                m = traces[0].meta().copy()
                for tr in traces[1:]:
                    trm = tr.meta()
                    rem = []
                    for k in m:
                        if k not in trm or trm[k] != m[k]:
                            rem.append(k)
                for k in rem:
                    m.pop(k)

                self._meta = m
            return self._meta
        
    def data(self):
        """Return a single array containing recorded data and stimuli from all channels recorded
        during this sweep.
        
        The array shape is (channels, samples, 2).
        """
        traces = self.traces()
        chan_data = [traces[ch].data() for ch in sorted(list(traces))]
        arr = np.empty((len(chan_data),) + chan_data[0].shape, chan_data[0].dtype)
        for i,data in enumerate(chan_data):
            arr[i] = data
        return arr

    def shape(self):
        return (len(self.channels()), len(self.traces().values()[0]))

    def describe(self):
        """Return a string description of this sweep.
        """
        return "\n".join(map(repr, self.traces().values()))

    def start_time(self):
        return MiesNwb.igorpro_date(self.meta()['TimeStamp'])


class SweepGroup(object):
    """Represents a collection of Sweeps that were acquired contiguously and
    all share the same stimulus parameters.
    """
    def __init__(self, nwb, sweeps):
        self.nwb = nwb
        self.sweeps = sweeps
        
    def meta(self):
        """Return metadata from the first sweep in this group.
        """
        return self.sweeps[0].meta()
        
    def data(self):
        """Return a single array containing all data from all sweeps in this
        group.
        
        The array shape is (sweeps, channels, samples, 2).
        """
        return self.nwb.pack_sweep_data(self.sweeps)

    def describe(self):
        """Return a string description of this group (taken from the first sweep).
        """
        return self.sweeps[0].describe()

    def __repr__(self):
        ids = self.sweeps[0].sweep_id, self.sweeps[-1].sweep_id
        return "<SweepGroup %d-%d>" % ids
